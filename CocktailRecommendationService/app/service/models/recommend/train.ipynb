{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Current GPU: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project\\OSS_Project\\AI\\myenv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Loss: 0.0222\n",
      "Epoch [20/300], Loss: 0.0184\n",
      "Epoch [30/300], Loss: 0.0173\n",
      "Epoch [40/300], Loss: 0.0169\n",
      "Epoch [50/300], Loss: 0.0163\n",
      "Epoch [60/300], Loss: 0.0159\n",
      "Epoch [70/300], Loss: 0.0155\n",
      "Epoch [80/300], Loss: 0.0148\n",
      "Epoch [90/300], Loss: 0.0139\n",
      "Epoch [100/300], Loss: 0.0133\n",
      "Epoch [110/300], Loss: 0.0127\n",
      "Epoch [120/300], Loss: 0.0116\n",
      "Epoch [130/300], Loss: 0.0116\n",
      "Epoch [140/300], Loss: 0.0109\n",
      "Epoch [150/300], Loss: 0.0103\n",
      "Epoch [160/300], Loss: 0.0102\n",
      "Epoch [170/300], Loss: 0.0099\n",
      "Epoch [180/300], Loss: 0.0095\n",
      "Epoch [190/300], Loss: 0.0093\n",
      "Epoch [200/300], Loss: 0.0089\n",
      "Epoch [210/300], Loss: 0.0088\n",
      "Epoch [220/300], Loss: 0.0085\n",
      "Epoch [230/300], Loss: 0.0083\n",
      "Epoch [240/300], Loss: 0.0083\n",
      "Epoch [250/300], Loss: 0.0083\n",
      "Epoch [260/300], Loss: 0.0081\n",
      "Epoch [270/300], Loss: 0.0081\n",
      "Epoch [280/300], Loss: 0.0080\n",
      "Epoch [290/300], Loss: 0.0083\n",
      "Epoch [300/300], Loss: 0.0078\n",
      "Model saved to 'model/deeper_multi_label_model.pt'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# 데이터셋 로드 및 전처리\n",
    "def load_and_preprocess_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    vectorizer = CountVectorizer()\n",
    "    data['cleaned_ingredients'] = data['ingredients'].apply(eval).apply(\n",
    "        lambda x: [''.join(ingredient.lower().split()) for ingredient in x]\n",
    "    )\n",
    "    data['ingredient_text'] = data['cleaned_ingredients'].apply(' '.join)\n",
    "    ingredient_vectors = vectorizer.fit_transform(data['ingredient_text']).toarray()\n",
    "\n",
    "    # 데이터 정규화\n",
    "    scaler = StandardScaler()\n",
    "    ingredient_vectors = scaler.fit_transform(ingredient_vectors)\n",
    "\n",
    "    cocktail_labels = {name: idx for idx, name in enumerate(data['name'].unique())}\n",
    "    data['labels'] = data['name'].map(cocktail_labels)\n",
    "\n",
    "    # 벡터라이저 저장\n",
    "    with open(\"model/vectorizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "\n",
    "    return data, ingredient_vectors, cocktail_labels\n",
    "\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, ingredient_vectors, labels, num_classes):\n",
    "        self.X = torch.tensor(ingredient_vectors, dtype=torch.float32)\n",
    "        self.y = torch.nn.functional.one_hot(\n",
    "            torch.tensor(labels, dtype=torch.long), num_classes=num_classes\n",
    "        ).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# 더 깊은 네트워크 모델 정의\n",
    "class DeeperMultiLabelClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(DeeperMultiLabelClassifier, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 2048)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(2048)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.dropout1 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(2048, 1024)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(1024)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(1024, 512)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(512)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.dropout3 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(512, 256)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(256)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "        self.dropout4 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc5 = torch.nn.Linear(256, 128)\n",
    "        self.bn5 = torch.nn.BatchNorm1d(128)\n",
    "        self.relu5 = torch.nn.ReLU()\n",
    "        self.dropout5 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc6 = torch.nn.Linear(128, num_classes)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.relu1(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout2(self.relu2(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout3(self.relu3(self.bn3(self.fc3(x))))\n",
    "        x = self.dropout4(self.relu4(self.bn4(self.fc4(x))))\n",
    "        x = self.dropout5(self.relu5(self.bn5(self.fc5(x))))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# 손실 함수 정의\n",
    "class LabelSmoothingLoss(torch.nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = targets * (1 - self.smoothing) + self.smoothing / targets.size(1)\n",
    "        return torch.nn.BCELoss()(inputs, targets)\n",
    "\n",
    "\n",
    "# 학습 코드\n",
    "def train_deeper_model(data_path, model_save_path, epochs=300, batch_size=16):\n",
    "    data, ingredient_vectors, cocktail_labels = load_and_preprocess_data(data_path)\n",
    "    dataset = MultiLabelDataset(ingredient_vectors, data['labels'].tolist(), num_classes=len(cocktail_labels))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = DeeperMultiLabelClassifier(input_size=ingredient_vectors.shape[1], num_classes=len(cocktail_labels))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "    criterion = LabelSmoothingLoss(smoothing=0.1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for inputs, targets in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        scheduler.step(total_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to '{model_save_path}'.\")\n",
    "\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    train_deeper_model(\n",
    "        data_path=\"data/final_cocktails.csv\",\n",
    "        model_save_path=\"model/deeper_multi_label_model.pt\",\n",
    "        epochs=300,\n",
    "        batch_size=16\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Recommendations:\n",
      "Screwdriver: 0.42\n",
      "Godmother: 0.33\n",
      "Lone Tree Cocktail: 0.30\n",
      "Iced Coffee Fillip: 0.27\n",
      "Rum Screwdriver: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_49096\\3932997113.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# 모델 정의 (학습 시 사용한 동일한 모델 구조)\n",
    "class DeepMultiLabelClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(DeepMultiLabelClassifier, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 1024)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(1024)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.dropout1 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(1024, 512)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(512)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(512, 256)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(256)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.dropout3 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(256, 128)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(128)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "        self.dropout4 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc5 = torch.nn.Linear(128, num_classes)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.relu1(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout2(self.relu2(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout3(self.relu3(self.bn3(self.fc3(x))))\n",
    "        x = self.dropout4(self.relu4(self.bn4(self.fc4(x))))\n",
    "        x = self.sigmoid(self.fc5(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# 테스트 함수 정의\n",
    "def test_model(model_path, vectorizer_path, data_path, test_ingredients, top_n=5):\n",
    "    \"\"\"\n",
    "    학습된 모델을 사용하여 테스트 입력에 대한 추천 결과를 출력합니다.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): 학습된 모델 파일 경로\n",
    "        vectorizer_path (str): 학습된 CountVectorizer 파일 경로\n",
    "        data_path (str): 데이터셋 파일 경로\n",
    "        test_ingredients (list): 테스트 입력 재료 리스트\n",
    "        top_n (int): 출력할 추천 결과의 개수\n",
    "    \"\"\"\n",
    "    # 벡터라이저 로드\n",
    "    with open(vectorizer_path, \"rb\") as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "\n",
    "    # 데이터셋 로드\n",
    "    data = pd.read_csv(data_path)\n",
    "    cocktail_labels = {name: idx for idx, name in enumerate(data['name'].unique())}\n",
    "    idx_to_label = {idx: name for name, idx in cocktail_labels.items()}\n",
    "    num_classes = len(cocktail_labels)\n",
    "\n",
    "    # 모델 초기화 및 로드\n",
    "    input_size = len(vectorizer.get_feature_names_out())\n",
    "    model = DeepMultiLabelClassifier(input_size=input_size, num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    # 테스트 입력 처리\n",
    "    test_vector = vectorizer.transform([' '.join(test_ingredients)]).toarray()\n",
    "    test_tensor = torch.tensor(test_vector, dtype=torch.float32)\n",
    "\n",
    "    # 예측 수행\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_tensor).flatten()\n",
    "        predicted_indices = torch.topk(outputs, k=top_n).indices.numpy()\n",
    "\n",
    "    # 추천 결과 출력\n",
    "    recommendations = [(idx_to_label[idx], outputs[idx].item()) for idx in predicted_indices]\n",
    "    print(\"Top Recommendations:\")\n",
    "    for name, score in recommendations:\n",
    "        print(f\"{name}: {score:.2f}\")\n",
    "\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 테스트 입력 예제\n",
    "    test_ingredients = [\"baileys\", \"chocolatesyrup\", \"milk\"]\n",
    "\n",
    "    # 테스트 코드 실행\n",
    "    test_model(\n",
    "        model_path=\"model/deep_multi_label_model.pt\",\n",
    "        vectorizer_path=\"model/vectorizer.pkl\",\n",
    "        data_path=\"data/final_cocktails.csv\",\n",
    "        test_ingredients=test_ingredients,\n",
    "        top_n=5  # 상위 5개 추천 결과 출력\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
