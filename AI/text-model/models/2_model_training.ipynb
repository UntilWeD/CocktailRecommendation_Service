{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4.68547248840332\n",
      "Epoch 0, Loss: 3.8798367977142334\n",
      "Epoch 0, Loss: 4.586738586425781\n",
      "Epoch 0, Loss: 4.591320514678955\n",
      "Epoch 0, Loss: 4.757419586181641\n",
      "Epoch 0, Loss: 4.0418572425842285\n",
      "Epoch 0, Loss: 4.290745258331299\n",
      "Epoch 0, Loss: 4.452389240264893\n",
      "Epoch 0, Loss: 4.3101806640625\n",
      "Epoch 0, Loss: 3.9708962440490723\n",
      "Epoch 0, Loss: 3.8853495121002197\n",
      "Epoch 0, Loss: 4.67462158203125\n",
      "Epoch 0, Loss: 3.611929416656494\n",
      "Epoch 1, Loss: 4.214059829711914\n",
      "Epoch 1, Loss: 3.9474401473999023\n",
      "Epoch 1, Loss: 4.104005813598633\n",
      "Epoch 1, Loss: 3.7866482734680176\n",
      "Epoch 1, Loss: 3.8137824535369873\n",
      "Epoch 1, Loss: 5.470815658569336\n",
      "Epoch 1, Loss: 4.548715114593506\n",
      "Epoch 1, Loss: 4.430315017700195\n",
      "Epoch 1, Loss: 4.050725936889648\n",
      "Epoch 1, Loss: 4.201711177825928\n",
      "Epoch 1, Loss: 4.132125377655029\n",
      "Epoch 1, Loss: 4.154841899871826\n",
      "Epoch 1, Loss: 3.373337984085083\n",
      "Epoch 2, Loss: 3.4883337020874023\n",
      "Epoch 2, Loss: 3.9418561458587646\n",
      "Epoch 2, Loss: 4.261086463928223\n",
      "Epoch 2, Loss: 5.368455410003662\n",
      "Epoch 2, Loss: 3.669651746749878\n",
      "Epoch 2, Loss: 4.48187255859375\n",
      "Epoch 2, Loss: 4.917544364929199\n",
      "Epoch 2, Loss: 5.02473258972168\n",
      "Epoch 2, Loss: 4.028549671173096\n",
      "Epoch 2, Loss: 3.8946475982666016\n",
      "Epoch 2, Loss: 3.7183949947357178\n",
      "Epoch 2, Loss: 3.925105333328247\n",
      "Epoch 2, Loss: 3.4369654655456543\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models/bert_model does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# 모델 저장\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/bert_model/model.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/bert_model/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모델 저장 완료\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\바탕 화면\\project\\OSS_Project\\AI\\myenv\\Lib\\site-packages\\torch\\serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    850\u001b[0m         _save(\n\u001b[0;32m    851\u001b[0m             obj,\n\u001b[0;32m    852\u001b[0m             opened_zipfile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[0;32m    856\u001b[0m         )\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\바탕 화면\\project\\OSS_Project\\AI\\myenv\\Lib\\site-packages\\torch\\serialization.py:716\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\바탕 화면\\project\\OSS_Project\\AI\\myenv\\Lib\\site-packages\\torch\\serialization.py:687\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory models/bert_model does not exist."
     ]
    }
   ],
   "source": [
    "# 커스텀 모델 클래스 정의\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier_도수 = nn.Linear(768, 3)  # 낮은, 중간, 높은\n",
    "        self.classifier_술종류 = nn.Linear(768, 4)  # 칵테일, 럼, 위스키, 보드카\n",
    "        self.classifier_맛 = nn.Linear(768, 5)  # 달달한, 쓴, 상큼한, 신맛, 부드러운\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[0][:, 0, :]  # CLS 토큰의 출력\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        return {\n",
    "            '도수': self.classifier_도수(pooled_output),\n",
    "            '술종류': self.classifier_술종류(pooled_output),\n",
    "            '맛': self.classifier_맛(pooled_output)\n",
    "        }\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv(r\"C:\\Users\\user\\OneDrive\\바탕 화면\\project\\OSS_Project\\AI\\text-model\\data\\processed_data.csv\")\n",
    "inputs = tokenizer(list(data['입력 문장']), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# 레이블 매핑\n",
    "도수_매핑 = {'낮은': 0, '중간': 1, '높은': 2}\n",
    "술종류_매핑 = {'칵테일': 0, '럼': 1, '위스키': 2, '보드카': 3}\n",
    "맛_매핑 = {'달달한': 0, '쓴맛': 1, '상큼한': 2, '신맛': 3, '부드러운': 4}\n",
    "\n",
    "# 레이블 변환\n",
    "도수_labels = torch.tensor([도수_매핑[도수] for 도수 in data['도수']])\n",
    "술종류_labels = torch.tensor([술종류_매핑[종류] for 종류 in data['술 종류']])\n",
    "맛_labels = torch.tensor([맛_매핑[맛] for 맛 in data['맛']])\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    inputs['input_ids'], \n",
    "    inputs['attention_mask'], \n",
    "    도수_labels,\n",
    "    술종류_labels,\n",
    "    맛_labels\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 모델 초기화\n",
    "model = MultiLabelClassifier()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        input_ids, attention_mask, 도수_label, 술종류_label, 맛_label = batch\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # 각 분류기의 손실 계산\n",
    "        도수_loss = loss_fn(outputs['도수'], 도수_label)\n",
    "        술종류_loss = loss_fn(outputs['술종류'], 술종류_label)\n",
    "        맛_loss = loss_fn(outputs['맛'], 맛_label)\n",
    "        \n",
    "        # 전체 손실 계산\n",
    "        total_loss = 도수_loss + 술종류_loss + 맛_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss.item()}\")\n",
    "\n",
    "# 모델 저장\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, \"models/bert_model/model.pt\")\n",
    "tokenizer.save_pretrained(\"bert_model/\")\n",
    "print(\"모델 저장 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
